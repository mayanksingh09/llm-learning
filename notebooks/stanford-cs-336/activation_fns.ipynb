{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/mayanksingh/CursorProjects/llm-learning/scripts/stanford-cs-336\")\n",
    "\n",
    "from activation_fns import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " [[ 0.63920015  0.19686274  0.58490583  0.37282176  1.82651257]\n",
      " [ 1.55824616  0.02742765  0.96635654 -0.94052587 -1.12703231]\n",
      " [-0.13229974  0.37791125 -0.54468632  0.64648672 -0.16345308]\n",
      " [ 1.76546546  0.83223129 -0.42518581 -0.98849573 -0.78774328]]\n",
      "Input shape:  (4, 128)\n",
      "--------------------------------------------------\n",
      "ReLU: \n",
      " [[0.63920015 0.19686274 0.58490583 0.37282176 1.82651257]\n",
      " [1.55824616 0.02742765 0.96635654 0.         0.        ]\n",
      " [0.         0.37791125 0.         0.64648672 0.        ]\n",
      " [1.76546546 0.83223129 0.         0.         0.        ]]\n",
      "ReLU shape:  (4, 128)\n",
      "--------------------------------------------------\n",
      "Tanh: \n",
      " [[ 0.5643547   0.19435842  0.52622194  0.35645741  0.94948377]\n",
      " [ 0.91513587  0.02742077  0.74709883 -0.73546377 -0.81000113]\n",
      " [-0.13153322  0.36089213 -0.49652713  0.5693001  -0.16201282]\n",
      " [ 0.9431103   0.68167228 -0.40129018 -0.75672017 -0.65712871]]\n",
      "Tanh shape:  (4, 128)\n",
      "--------------------------------------------------\n",
      "Softmax: \n",
      " [[0.14177693 0.20282607 0.31728323 0.35211077 0.79234476]\n",
      " [0.35542027 0.17121391 0.46463194 0.09468903 0.04132434]\n",
      " [0.06554619 0.24308164 0.10253485 0.46294616 0.10831362]\n",
      " [0.43725661 0.38287837 0.11554999 0.09025404 0.05801727]]\n",
      "Softmax shape:  (4, 128)\n",
      "--------------------------------------------------\n",
      "Swish: \n",
      " [[ 0.41840293  0.10808894  0.37562387  0.22076292  1.57325884]\n",
      " [ 1.28726956  0.01390188  0.70002161 -0.26409415 -0.27579517]\n",
      " [-0.06178044  0.2242409  -0.19995331  0.42423643 -0.07506215]\n",
      " [ 1.50751833  0.57992083 -0.16806596 -0.26808924 -0.24629064]]\n",
      "Swish shape:  (4, 128)\n",
      "--------------------------------------------------\n",
      "GLU: \n",
      " [[-0.55036606 -0.63594332  0.54539661  0.12002536 -0.53640843]\n",
      " [ 2.00578166  0.95528441  0.67260953 -0.13794308  0.35417504]\n",
      " [ 0.27296151  0.3875104   0.42055272  0.79025297 -0.11268141]\n",
      " [ 0.26451696  0.55993244  0.36434742 -0.36850523 -0.09656805]]\n",
      "GLU shape:  (4, 128)\n",
      "--------------------------------------------------\n",
      "SwiGLU: \n",
      " [[-1.19276927 -0.18298546  1.79456904 -0.02989462  0.04746048]\n",
      " [ 0.18991728 -0.24992039  0.3384636   0.09504249 -2.02175606]\n",
      " [ 0.04921675  0.80977356  0.37564139  0.51745877  1.89000469]\n",
      " [ 1.77571011  0.26875126 -0.11488384  0.19070666  0.01216457]]\n",
      "SwiGLU shape:  (4, 128)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch, d_in, d_out = 4, 128, 128 # batch size, input feature dimension, output feature dimension\n",
    "\n",
    "x = np.random.randn(batch, d_in)\n",
    "\n",
    "print(\"Input: \\n\", x[:5, :5])\n",
    "print(\"Input shape: \", x.shape)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "y_relu = relu(x)\n",
    "print(\"ReLU: \\n\", y_relu[:5, :5])\n",
    "print(\"ReLU shape: \", y_relu.shape)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "y_tanh = tanh(x)\n",
    "print(\"Tanh: \\n\", y_tanh[:5, :5])\n",
    "print(\"Tanh shape: \", y_tanh.shape)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "y_softmax = softmax(x)\n",
    "print(\"Softmax: \\n\", y_softmax[:5, :5])\n",
    "print(\"Softmax shape: \", y_softmax.shape)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "y_swish = swish(x)\n",
    "print(\"Swish: \\n\", y_swish[:5, :5])\n",
    "print(\"Swish shape: \", y_swish.shape)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "glu_layer = GLU(d_in, d_out)\n",
    "y_glu = glu_layer(x)\n",
    "print(\"GLU: \\n\", y_glu[:5, :5])\n",
    "print(\"GLU shape: \", y_glu.shape)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "swiglu_layer = SwiGLU(d_in, d_out)\n",
    "y_swiglu = swiglu_layer(x)\n",
    "print(\"SwiGLU: \\n\", y_swiglu[:5, :5])\n",
    "print(\"SwiGLU shape: \", y_swiglu.shape)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-learning",
   "language": "python",
   "name": "llm-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
